{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# import xgboost as xgb\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from datetime import datetime\n",
    "\n",
    "# data_file = \"/home/awias/data/Summerschool_2025/metadata_more.csv\"\n",
    "\n",
    "# # Load your CSV file\n",
    "# df = pd.read_csv(data_file)\n",
    "\n",
    "# # Display basic info about the dataset\n",
    "# print(\"Dataset shape:\", df.shape)\n",
    "# print(\"\\nColumn info:\")\n",
    "# print(df.info())\n",
    "# print(\"\\nFirst few rows:\")\n",
    "# print(df.head())\n",
    "\n",
    "# # Check for missing values\n",
    "# print(\"\\nMissing values:\")\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "# # Remove rows where taxonID_index is missing (since it's our target)\n",
    "# df_clean = df.dropna(subset=['taxonID_index']).copy()\n",
    "# print(f\"\\nRows after removing missing targets: {len(df_clean)}\")\n",
    "\n",
    "# # Skip date feature engineering for now\n",
    "# print(\"Skipping eventDate features as requested...\")\n",
    "\n",
    "# # Prepare features for modeling (excluding eventDate features)\n",
    "# feature_columns = ['Habitat', 'Latitude', 'Longitude', 'Substrate']\n",
    "\n",
    "# # Remove rows with missing values in feature columns\n",
    "# df_model = df_clean.dropna(subset=feature_columns).copy()\n",
    "# print(f\"\\nRows after removing missing features: {len(df_model)}\")\n",
    "\n",
    "# # Encode categorical variables\n",
    "# label_encoders = {}\n",
    "# categorical_features = ['Habitat', 'Substrate']\n",
    "\n",
    "# for col in categorical_features:\n",
    "#     le = LabelEncoder()\n",
    "#     df_model[col + '_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "#     label_encoders[col] = le\n",
    "#     print(f\"\\n{col} categories: {le.classes_}\")\n",
    "\n",
    "# # Prepare final feature matrix (without date features)\n",
    "# feature_cols_final = ['Habitat_encoded', 'Latitude', 'Longitude', 'Substrate_encoded']\n",
    "\n",
    "# X = df_model[feature_cols_final]\n",
    "# y = df_model['taxonID_index']\n",
    "\n",
    "# # Encode target variable if it's categorical\n",
    "# target_encoder = LabelEncoder()\n",
    "# y_encoded = target_encoder.fit_transform(y.astype(str))\n",
    "\n",
    "# print(f\"\\nNumber of unique target classes: {len(target_encoder.classes_)}\")\n",
    "# print(f\"Target classes: {target_encoder.classes_[:10]}...\")  # Show first 10\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "# )\n",
    "\n",
    "# print(f\"\\nTraining set size: {X_train.shape}\")\n",
    "# print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# # Train XGBoost model with GPU support\n",
    "# print(\"\\nTraining XGBoost model on GPU...\")\n",
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     n_estimators=200,\n",
    "#     max_depth=8,\n",
    "#     learning_rate=0.1,\n",
    "#     random_state=42,\n",
    "#     eval_metric='mlogloss' if len(np.unique(y_encoded)) > 2 else 'logloss',\n",
    "#     tree_method='gpu_hist',  # Use GPU for training\n",
    "#     gpu_id=0,  # Use first GPU\n",
    "#     early_stopping_rounds=10\n",
    "# )\n",
    "\n",
    "# # Add validation set for early stopping\n",
    "# X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "# )\n",
    "\n",
    "# xgb_model.fit(\n",
    "#     X_train_split, y_train_split,\n",
    "#     eval_set=[(X_val, y_val)],\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = xgb_model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"\\nModel Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# # Feature Importance Analysis\n",
    "# feature_importance = xgb_model.feature_importances_\n",
    "# feature_names = X.columns\n",
    "\n",
    "# # Create feature importance dataframe\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'feature': feature_names,\n",
    "#     'importance': feature_importance\n",
    "# }).sort_values('importance', ascending=False)\n",
    "\n",
    "# print(\"\\nFeature Importance Ranking:\")\n",
    "# print(importance_df)\n",
    "\n",
    "# # Plot feature importance\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.barplot(data=importance_df, y='feature', x='importance')\n",
    "# plt.title('XGBoost Feature Importance for Fungi Classification')\n",
    "# plt.xlabel('Feature Importance')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # More detailed analysis\n",
    "# print(\"\\nDetailed Feature Analysis:\")\n",
    "# for idx, row in importance_df.iterrows():\n",
    "#     feature = row['feature']\n",
    "#     importance = row['importance']\n",
    "#     print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "#     # Show some statistics for this feature\n",
    "#     if feature in X.columns:\n",
    "#         feature_stats = X[feature].describe()\n",
    "#         print(f\"  Min: {feature_stats['min']:.2f}, Max: {feature_stats['max']:.2f}, Mean: {feature_stats['mean']:.2f}\")\n",
    "#     print()\n",
    "\n",
    "# # Create a correlation matrix for numerical features\n",
    "# numerical_features = ['Latitude', 'Longitude']\n",
    "# if len(numerical_features) > 1:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     correlation_matrix = X[numerical_features].corr()\n",
    "#     sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "#     plt.title('Correlation Matrix of Numerical Features')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Print decoded categorical mappings for interpretation\n",
    "# print(\"\\nCategorical Feature Mappings:\")\n",
    "# for col in categorical_features:\n",
    "#     le = label_encoders[col]\n",
    "#     mapping = dict(zip(range(len(le.classes_)), le.classes_))\n",
    "#     print(f\"\\n{col}:\")\n",
    "#     for code, category in mapping.items():\n",
    "#         print(f\"  {code}: {category}\")\n",
    "\n",
    "# # Show target distribution\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# target_counts = pd.Series(y_encoded).value_counts().sort_index()\n",
    "# plt.bar(range(len(target_counts)), target_counts.values)\n",
    "# plt.title('Distribution of Target Classes')\n",
    "# plt.xlabel('Encoded Target Class')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(range(0, len(target_counts), max(1, len(target_counts)//20)))\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"\\nTarget distribution summary:\")\n",
    "# print(f\"Total classes: {len(target_counts)}\")\n",
    "# print(f\"Most common class frequency: {target_counts.max()}\")\n",
    "# print(f\"Least common class frequency: {target_counts.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09523c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "data_file = \"/home/awias/data/Summerschool_2025/metadata_more.csv\"\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Only keep the records where the substring 'train' is in filename_index\n",
    "df = df[df['filename_index'].str.contains('train', na=False)].copy()\n",
    "\n",
    "# Remove rows where taxonID_index is missing (since it's our target)\n",
    "df_clean = df.dropna(subset=['taxonID_index']).copy()\n",
    "\n",
    "# Remove 'eventDate' column\n",
    "df_clean = df_clean.drop(columns=['eventDate'], errors='ignore')\n",
    "\n",
    "# Remove rows where at least two of the specified columns are NaN\n",
    "cols_to_check = ['Habitat', 'Latitude', 'Longitude', 'Substrate']\n",
    "df_clean = df_clean[df_clean[cols_to_check].isnull().sum(axis=1) < 2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1231f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename_index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Habitat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Substrate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "taxonID_index",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "15c8d635-ee14-44ad-9f1b-ec0486059c0b",
       "rows": [
        [
         "10161",
         "fungi_train000009.jpg",
         "coniferous woodland/plantation",
         "56.016904",
         "12.003886",
         "soil",
         "180.0"
        ],
        [
         "10164",
         "fungi_train000012.jpg",
         "natural grassland",
         "54.9812",
         "9.75912",
         "soil",
         "37.0"
        ],
        [
         "10172",
         "fungi_train000020.jpg",
         "Unmanaged coniferous woodland",
         "54.991672",
         "15.075319",
         "soil",
         "54.0"
        ],
        [
         "10188",
         "fungi_train000036.jpg",
         "Mixed woodland (with coniferous and deciduous trees)",
         "55.605675",
         "8.337206",
         "soil",
         "15.0"
        ],
        [
         "10202",
         "fungi_train000050.jpg",
         "Unmanaged coniferous woodland",
         "55.254991",
         "12.156747",
         "leaf or needle litter",
         "72.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_index</th>\n",
       "      <th>Habitat</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Substrate</th>\n",
       "      <th>taxonID_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>fungi_train000009.jpg</td>\n",
       "      <td>coniferous woodland/plantation</td>\n",
       "      <td>56.016904</td>\n",
       "      <td>12.003886</td>\n",
       "      <td>soil</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>fungi_train000012.jpg</td>\n",
       "      <td>natural grassland</td>\n",
       "      <td>54.981200</td>\n",
       "      <td>9.759120</td>\n",
       "      <td>soil</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>fungi_train000020.jpg</td>\n",
       "      <td>Unmanaged coniferous woodland</td>\n",
       "      <td>54.991672</td>\n",
       "      <td>15.075319</td>\n",
       "      <td>soil</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10188</th>\n",
       "      <td>fungi_train000036.jpg</td>\n",
       "      <td>Mixed woodland (with coniferous and deciduous ...</td>\n",
       "      <td>55.605675</td>\n",
       "      <td>8.337206</td>\n",
       "      <td>soil</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>fungi_train000050.jpg</td>\n",
       "      <td>Unmanaged coniferous woodland</td>\n",
       "      <td>55.254991</td>\n",
       "      <td>12.156747</td>\n",
       "      <td>leaf or needle litter</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename_index  \\\n",
       "10161  fungi_train000009.jpg   \n",
       "10164  fungi_train000012.jpg   \n",
       "10172  fungi_train000020.jpg   \n",
       "10188  fungi_train000036.jpg   \n",
       "10202  fungi_train000050.jpg   \n",
       "\n",
       "                                                 Habitat   Latitude  \\\n",
       "10161                     coniferous woodland/plantation  56.016904   \n",
       "10164                                  natural grassland  54.981200   \n",
       "10172                      Unmanaged coniferous woodland  54.991672   \n",
       "10188  Mixed woodland (with coniferous and deciduous ...  55.605675   \n",
       "10202                      Unmanaged coniferous woodland  55.254991   \n",
       "\n",
       "       Longitude              Substrate  taxonID_index  \n",
       "10161  12.003886                   soil          180.0  \n",
       "10164   9.759120                   soil           37.0  \n",
       "10172  15.075319                   soil           54.0  \n",
       "10188   8.337206                   soil           15.0  \n",
       "10202  12.156747  leaf or needle litter           72.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a65b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_features = ['Habitat', 'Substrate']\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col + '_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Prepare final feature matrix (without date features)\n",
    "feature_cols_final = ['Habitat_encoded', 'Latitude', 'Longitude', 'Substrate_encoded']\n",
    "\n",
    "X = df_clean[feature_cols_final]\n",
    "y = df_clean['taxonID_index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3c9ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Habitat_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Substrate_encoded",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "097c8b4a-f4a9-4d22-8576-2f29b07d96f9",
       "rows": [
        [
         "10161",
         "10",
         "56.016904",
         "12.003886",
         "11"
        ],
        [
         "10164",
         "21",
         "54.9812",
         "9.75912",
         "11"
        ],
        [
         "10172",
         "6",
         "54.991672",
         "15.075319",
         "11"
        ],
        [
         "10188",
         "4",
         "55.605675",
         "8.337206",
         "11"
        ],
        [
         "10202",
         "6",
         "55.254991",
         "12.156747",
         "6"
        ],
        [
         "10214",
         "10",
         "55.68455",
         "12.35765",
         "12"
        ],
        [
         "10219",
         "2",
         "55.898398",
         "12.004236",
         "11"
        ],
        [
         "10222",
         "16",
         "56.97006999999999",
         "9.51357",
         "11"
        ],
        [
         "10232",
         "2",
         "55.816185",
         "12.309158",
         "4"
        ],
        [
         "10237",
         "24",
         "54.773785",
         "11.365993",
         "11"
        ],
        [
         "10242",
         "4",
         "55.103123",
         "10.534447",
         "4"
        ],
        [
         "10243",
         "10",
         "55.99491999999999",
         "12.30051",
         "11"
        ],
        [
         "10255",
         "19",
         "57.11552800000001",
         "8.660446",
         "11"
        ],
        [
         "10256",
         "5",
         "56.64840600000001",
         "9.817357",
         "11"
        ],
        [
         "10272",
         "23",
         "56.12718100000001",
         "10.209567",
         "11"
        ],
        [
         "10280",
         "10",
         "56.023331000000006",
         "12.34672",
         "6"
        ],
        [
         "10286",
         "10",
         "56.49548000000001",
         "10.77896",
         "11"
        ],
        [
         "10290",
         "4",
         "55.197481",
         "11.827904",
         "11"
        ],
        [
         "10296",
         "6",
         "56.058128",
         "9.227258",
         "11"
        ],
        [
         "10298",
         "10",
         "57.201265",
         "10.289844",
         "4"
        ],
        [
         "10299",
         "4",
         "55.6217",
         "11.92578",
         "11"
        ],
        [
         "10307",
         "2",
         "56.108714",
         "9.675111",
         "11"
        ],
        [
         "10309",
         "7",
         "55.963249",
         "12.384367",
         "11"
        ],
        [
         "10313",
         "2",
         "55.56591",
         "11.892464",
         "11"
        ],
        [
         "10324",
         "10",
         "56.020646",
         "9.902943",
         "7"
        ],
        [
         "10325",
         "13",
         "55.60586",
         "11.98209",
         "8"
        ],
        [
         "10337",
         "10",
         "56.045774",
         "12.077889",
         "11"
        ],
        [
         "10344",
         "2",
         "55.77204",
         "12.43601",
         "11"
        ],
        [
         "10347",
         "2",
         "56.02499",
         "12.33489",
         "11"
        ],
        [
         "10352",
         "7",
         "55.379891",
         "10.42636",
         "11"
        ],
        [
         "10359",
         "7",
         "56.258931",
         "10.629758",
         "11"
        ],
        [
         "10362",
         "4",
         "55.16416",
         "14.709320000000002",
         "11"
        ],
        [
         "10372",
         "2",
         "56.02336999999999",
         "12.33904",
         "11"
        ],
        [
         "10392",
         "10",
         "56.063148",
         "9.293189",
         "11"
        ],
        [
         "10393",
         "2",
         "55.075036",
         "15.048236",
         "4"
        ],
        [
         "10396",
         "2",
         "55.57338299999999",
         "12.576207",
         "11"
        ],
        [
         "10433",
         "3",
         "55.88395300000001",
         "12.322731",
         "11"
        ],
        [
         "10438",
         "10",
         "55.29485",
         "12.16032",
         "11"
        ],
        [
         "10439",
         "2",
         "55.456935",
         "12.148107",
         "11"
        ],
        [
         "10452",
         "2",
         "55.498548",
         "9.488117",
         "11"
        ],
        [
         "10461",
         "4",
         "56.96921700000001",
         "9.502762",
         "11"
        ],
        [
         "10469",
         "4",
         "55.80104",
         "12.387328",
         "1"
        ],
        [
         "10489",
         "4",
         "55.146078",
         "10.388787",
         "4"
        ],
        [
         "10504",
         "23",
         "55.782558",
         "12.591168",
         "11"
        ],
        [
         "10512",
         "5",
         "56.64435600000001",
         "9.80725",
         "4"
        ],
        [
         "10520",
         "6",
         "55.79535",
         "11.499556",
         "4"
        ],
        [
         "10523",
         "6",
         "55.150811",
         "8.536033999999999",
         "11"
        ],
        [
         "10532",
         "7",
         "56.807281",
         "9.872975",
         "11"
        ],
        [
         "10536",
         "4",
         "56.826835",
         "9.815512",
         "11"
        ],
        [
         "10579",
         "5",
         "56.648374",
         "9.817641",
         "4"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3172
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Habitat_encoded</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Substrate_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>10</td>\n",
       "      <td>56.016904</td>\n",
       "      <td>12.003886</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>21</td>\n",
       "      <td>54.981200</td>\n",
       "      <td>9.759120</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>6</td>\n",
       "      <td>54.991672</td>\n",
       "      <td>15.075319</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10188</th>\n",
       "      <td>4</td>\n",
       "      <td>55.605675</td>\n",
       "      <td>8.337206</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>6</td>\n",
       "      <td>55.254991</td>\n",
       "      <td>12.156747</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35980</th>\n",
       "      <td>21</td>\n",
       "      <td>56.645327</td>\n",
       "      <td>9.817572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35982</th>\n",
       "      <td>10</td>\n",
       "      <td>56.627560</td>\n",
       "      <td>10.026530</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36006</th>\n",
       "      <td>14</td>\n",
       "      <td>55.891100</td>\n",
       "      <td>10.183600</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36009</th>\n",
       "      <td>23</td>\n",
       "      <td>55.783276</td>\n",
       "      <td>12.591566</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36010</th>\n",
       "      <td>18</td>\n",
       "      <td>55.820592</td>\n",
       "      <td>12.076083</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3172 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Habitat_encoded   Latitude  Longitude  Substrate_encoded\n",
       "10161               10  56.016904  12.003886                 11\n",
       "10164               21  54.981200   9.759120                 11\n",
       "10172                6  54.991672  15.075319                 11\n",
       "10188                4  55.605675   8.337206                 11\n",
       "10202                6  55.254991  12.156747                  6\n",
       "...                ...        ...        ...                ...\n",
       "35980               21  56.645327   9.817572                 11\n",
       "35982               10  56.627560  10.026530                  6\n",
       "36006               14  55.891100  10.183600                 11\n",
       "36009               23  55.783276  12.591566                 11\n",
       "36010               18  55.820592  12.076083                 11\n",
       "\n",
       "[3172 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42822cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique target classes: 181\n",
      "Target classes: ['0.0' '1.0' '10.0' '100.0' '101.0' '102.0' '103.0' '104.0' '105.0'\n",
      " '106.0']...\n",
      "\n",
      "Training set size: (2537, 4)\n",
      "Test set size: (635, 4)\n",
      "\n",
      "Training XGBoost model on GPU...\n"
     ]
    }
   ],
   "source": [
    "# Encode target variable if it's categorical\n",
    "target_encoder = LabelEncoder()\n",
    "y_encoded = target_encoder.fit_transform(y.astype(str))\n",
    "\n",
    "print(f\"\\nNumber of unique target classes: {len(target_encoder.classes_)}\")\n",
    "print(f\"Target classes: {target_encoder.classes_[:10]}...\")  # Show first 10\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Train XGBoost model with GPU support\n",
    "print(\"\\nTraining XGBoost model on GPU...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss' if len(np.unique(y_encoded)) > 2 else 'logloss',\n",
    "    tree_method='gpu_hist',  # Use GPU for training\n",
    "    gpu_id=0,  # Use first GPU\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff8804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awias/anaconda3/envs/standard/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [14:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:5.12577\n",
      "[1]\tvalidation_0-mlogloss:5.06117\n",
      "[2]\tvalidation_0-mlogloss:5.00558\n",
      "[3]\tvalidation_0-mlogloss:4.95554\n",
      "[4]\tvalidation_0-mlogloss:4.91063\n",
      "[5]\tvalidation_0-mlogloss:4.86931\n",
      "[6]\tvalidation_0-mlogloss:4.83326\n",
      "[7]\tvalidation_0-mlogloss:4.80228\n",
      "[8]\tvalidation_0-mlogloss:4.77165\n",
      "[9]\tvalidation_0-mlogloss:4.73966\n",
      "[10]\tvalidation_0-mlogloss:4.71541\n",
      "[11]\tvalidation_0-mlogloss:4.69120\n",
      "[12]\tvalidation_0-mlogloss:4.67275\n"
     ]
    }
   ],
   "source": [
    "# Add validation set for early stopping\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f488889f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred = \u001b[43mxgb_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m accuracy = accuracy_score(y_test, y_pred)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/standard/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/standard/lib/python3.12/site-packages/xgboost/sklearn.py:1719\u001b[39m, in \u001b[36mXGBClassifier.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1708\u001b[39m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[32m   1709\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m   1710\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1716\u001b[39m     iteration_range: Optional[IterationRange] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1717\u001b[39m ) -> ArrayLike:\n\u001b[32m   1718\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity=\u001b[38;5;28mself\u001b[39m.verbosity):\n\u001b[32m-> \u001b[39m\u001b[32m1719\u001b[39m         class_probs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1726\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[32m   1727\u001b[39m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[32m   1728\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/standard/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/standard/lib/python3.12/site-packages/xgboost/sklearn.py:1327\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1327\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.inplace_predict(\n\u001b[32m   1328\u001b[39m             data=X,\n\u001b[32m   1329\u001b[39m             iteration_range=iteration_range,\n\u001b[32m   1330\u001b[39m             predict_type=\u001b[33m\"\u001b[39m\u001b[33mmargin\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1331\u001b[39m             missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1332\u001b[39m             base_margin=base_margin,\n\u001b[32m   1333\u001b[39m             validate_features=validate_features,\n\u001b[32m   1334\u001b[39m         )\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1336\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/standard/lib/python3.12/site-packages/xgboost/sklearn.py:922\u001b[39m, in \u001b[36mXGBModel.get_booster\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__sklearn_is_fitted__():\n\u001b[32m    920\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mneed to call fit or load_model beforehand\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._Booster\n",
      "\u001b[31mNotFittedError\u001b[39m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=importance_df, y='feature', x='importance')\n",
    "plt.title('XGBoost Feature Importance for Fungi Classification')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# More detailed analysis\n",
    "print(\"\\nDetailed Feature Analysis:\")\n",
    "for idx, row in importance_df.iterrows():\n",
    "    feature = row['feature']\n",
    "    importance = row['importance']\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Show some statistics for this feature\n",
    "    if feature in X.columns:\n",
    "        feature_stats = X[feature].describe()\n",
    "        print(f\"  Min: {feature_stats['min']:.2f}, Max: {feature_stats['max']:.2f}, Mean: {feature_stats['mean']:.2f}\")\n",
    "    print()\n",
    "\n",
    "# Create a correlation matrix for numerical features\n",
    "numerical_features = ['Latitude', 'Longitude']\n",
    "if len(numerical_features) > 1:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    correlation_matrix = X[numerical_features].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix of Numerical Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Print decoded categorical mappings for interpretation\n",
    "print(\"\\nCategorical Feature Mappings:\")\n",
    "for col in categorical_features:\n",
    "    le = label_encoders[col]\n",
    "    mapping = dict(zip(range(len(le.classes_)), le.classes_))\n",
    "    print(f\"\\n{col}:\")\n",
    "    for code, category in mapping.items():\n",
    "        print(f\"  {code}: {category}\")\n",
    "\n",
    "# Show target distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "target_counts = pd.Series(y_encoded).value_counts().sort_index()\n",
    "plt.bar(range(len(target_counts)), target_counts.values)\n",
    "plt.title('Distribution of Target Classes')\n",
    "plt.xlabel('Encoded Target Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(0, len(target_counts), max(1, len(target_counts)//20)))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTarget distribution summary:\")\n",
    "print(f\"Total classes: {len(target_counts)}\")\n",
    "print(f\"Most common class frequency: {target_counts.max()}\")\n",
    "print(f\"Least common class frequency: {target_counts.min()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
