{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a8f09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from albumentations import RandomResizedCrop, HorizontalFlip, VerticalFlip, RandomBrightnessContrast\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tokenize_attributes():\n",
    "    \"\"\"\n",
    "    Tokenize attributes based on their type.\n",
    "    \"\"\"\n",
    "    def __init__(self, cameraModelSTxt, CameraMakerTxt):\n",
    "        self.habitat_types = ['Mixed woodland (with coniferous and deciduous trees)', 'Unmanaged deciduous woodland',\n",
    "                              'Forest bog', 'coniferous woodland/plantation', 'Deciduous woodland', 'natural grassland', 'lawn',\n",
    "                              'Unmanaged coniferous woodland', 'garden', 'wooded meadow, grazing forest', 'dune', 'Willow scrubland', 'heath',\n",
    "                              'Acidic oak woodland', 'roadside', 'Thorny scrubland', 'park/churchyard', 'Bog woodland', 'hedgerow', 'gravel or clay pit',\n",
    "                              'salt meadow', 'bog', 'meadow', 'improved grassland', 'other habitat', 'roof', 'fallow field', 'ditch', 'fertilized field in rotation']\n",
    "        \n",
    "        self.substrate_types = ['soil', 'leaf or needle litter', 'wood chips or mulch', 'dead wood (including bark)', 'bark',\n",
    "                                'wood', 'bark of living trees', 'mosses', 'wood and roots of living trees', 'stems of herbs, grass etc',\n",
    "                                'peat mosses','dead stems of herbs, grass etc', 'fungi', 'other substrate', 'living stems of herbs, grass etc',\n",
    "                                'living leaves', 'fire spot', 'faeces', 'cones', 'fruits']\n",
    "        #load the txt files with camera models and camera makers, the text file is already on the form of a list of strings\n",
    "        with open(cameraModelSTxt, \"r\", encoding=\"utf-8\") as f:\n",
    "            camera_models_types = f.read()\n",
    "        self.camera_models_types = ast.literal_eval(camera_models_types)\n",
    "        with open(CameraMakerTxt, \"r\", encoding=\"utf-8\") as f:\n",
    "            camera_makers_types = f.read()\n",
    "        self.camera_makers_types = ast.literal_eval(camera_makers_types)\n",
    "    \n",
    "    \n",
    "        self.habitat_types2idx = {habitat: idx for idx, habitat in enumerate(self.habitat_types)}\n",
    "        self.substrate_types2idx = {substrate: idx for idx, substrate in enumerate(self.substrate_types)}\n",
    "        self.camera_models2idx = {model: idx for idx, model in enumerate(self.camera_models_types)}\n",
    "        self.camera_makers2idx = {maker: idx for idx, maker in enumerate(self.camera_makers_types)}\n",
    "        \n",
    "        self.num_habitats = len(self.habitat_types) + 1  # +1 for 'missing habitat'\n",
    "        self.num_substrates = len(self.substrate_types) + 1  # +1 for 'missing substrate'\n",
    "        self.num_months = 12+1\n",
    "        self.num_hours = 24 # 0-23, +1 for 'missing hour'\n",
    "        self.num_camera_models = len(self.camera_models_types) + 1  # +1 for 'missing camera model'\n",
    "        self.num_camera_makers = len(self.camera_makers_types) + 1  # +1 for 'missing camera maker'\n",
    "        \n",
    "        \n",
    "    \n",
    "    def tokenize(self, attribute, attribute_type):\n",
    "        if attribute_type == 'Habitat':\n",
    "            if attribute not in self.habitat_types:\n",
    "                return len(self.habitat_types)  # Return index for 'missing habitat'\n",
    "            else:\n",
    "                return self.habitat_types2idx[attribute]\n",
    "        elif attribute_type == 'Substrate':\n",
    "            if attribute not in self.substrate_types:\n",
    "                return len(self.substrate_types)\n",
    "            else:\n",
    "                return self.substrate_types2idx[attribute]\n",
    "        elif attribute_type == 'DateTimeOriginal':\n",
    "            try:\n",
    "                # Expecting 'yyyy-mm-dd' format\n",
    "                yymmdd = attribute.split(' ')[0]\n",
    "                hhmmss = attribute.split(' ')[1]\n",
    "                month = int(yymmdd.split(':')[1])  # Extract month (1-12)\n",
    "                hour = int(hhmmss.split(':')[0])  # Extract hour (0-23)\n",
    "                \n",
    "                return month-1, hour  # Return month index (0-11)\n",
    "            except (IndexError, ValueError, AttributeError):\n",
    "                return self.num_months-1, self.num_hours  # or a default month token, e.g., 0\n",
    "        elif attribute_type == 'camera_model':\n",
    "            if attribute not in self.camera_models_types:\n",
    "                return len(self.camera_models_types)\n",
    "            else:\n",
    "                return self.camera_models2idx[attribute]\n",
    "        elif attribute_type == 'camera_maker':\n",
    "            if attribute not in self.camera_makers_types:\n",
    "                return len(self.camera_makers_types)\n",
    "            else:\n",
    "                return self.camera_makers2idx[attribute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "041d4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FungiDataset(Dataset):\n",
    "    def __init__(self, df, path, CameraMakerTxt, cameraModelSTxt, transform=None, multi_modal=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "        self.multi_modal = multi_modal\n",
    "        self.tokenizer = tokenize_attributes(CameraMakerTxt, cameraModelSTxt)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.df['filename_index'].values[idx]\n",
    "        # Get label if it exists; otherwise return None\n",
    "        label = self.df['taxonID_index'].values[idx]  # Get label\n",
    "        if pd.isnull(label):\n",
    "            label = -1  # Handle missing labels for the test dataset\n",
    "        else:\n",
    "            label = int(label)\n",
    "            \n",
    "        if self.multi_modal:\n",
    "            habitat = self.df['Habitat'].values[idx]\n",
    "            if pd.isnull(habitat):\n",
    "                habitat = -1\n",
    "            else:\n",
    "                habitat = str(habitat)\n",
    "            habitat = self.tokenizer.tokenize(habitat, 'Habitat')\n",
    "                \n",
    "            latitude = self.df['Latitude'].values[idx]\n",
    "            if pd.isnull(latitude):\n",
    "                latitude = -1\n",
    "            else:\n",
    "                latitude = float(latitude)\n",
    "            longitude = self.df['Longitude'].values[idx]\n",
    "            if pd.isnull(longitude):\n",
    "                longitude = -1\n",
    "            else:\n",
    "                longitude = float(longitude)\n",
    "            substrate = self.df['Substrate'].values[idx]\n",
    "            if pd.isnull(substrate):\n",
    "                substrate = -1\n",
    "            else:\n",
    "                substrate = str(substrate)\n",
    "            substrate = self.tokenizer.tokenize(substrate, 'Substrate')\n",
    "            eventDate = self.df['DateTimeOriginal'].values[idx]\n",
    "            if pd.isnull(eventDate):\n",
    "                month, hour = -1, -1\n",
    "            else:\n",
    "                eventDate = str(eventDate)\n",
    "            month, hour = self.tokenizer.tokenize(eventDate, 'DateTimeOriginal')\n",
    "            cameraModel = self.df['camera_model'].values[idx]\n",
    "            if pd.isnull(cameraModel):\n",
    "                cameraModel = -1\n",
    "            else:\n",
    "                cameraModel = str(cameraModel)\n",
    "            cameraModel = self.tokenizer.tokenize(cameraModel, 'camera_model')\n",
    "            cameraMaker = self.df['camera_maker'].values[idx]\n",
    "            if pd.isnull(cameraMaker):\n",
    "                cameraMaker = -1\n",
    "            else:\n",
    "                cameraMaker = str(cameraMaker)\n",
    "            cameraMaker = self.tokenizer.tokenize(cameraMaker, 'camera_maker')\n",
    "            \n",
    "        with Image.open(os.path.join(self.path, file_path)) as img:\n",
    "            # Convert to RGB mode (handles grayscale images as well)\n",
    "            image = img.convert('RGB')\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Apply transformations if available\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        if self.multi_modal:\n",
    "            return image, label, file_path, habitat, substrate, month, hour, cameraMaker, cameraModel, latitude, longitude\n",
    "        else:\n",
    "            return image, label, file_path\n",
    "\n",
    "def get_transforms(data):\n",
    "    \"\"\"\n",
    "    Return augmentation transforms for the specified mode ('train' or 'valid').\n",
    "    \"\"\"\n",
    "    width, height = 224, 224\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(size = (width, height), scale=(0.8, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(width, height),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"Unknown data mode requested (only 'train' or 'valid' allowed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5e9ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = str('C:/Users/bmsha/sc2025/metadata_1/metadata_with_camera_info.csv')\n",
    "df = pd.read_csv(data_file)\n",
    "train_df = df[df['filename_index'].str.startswith('fungi_train')]\n",
    "image_path = str(\"C:/Users/bmsha/sc2025/FungiImages\")\n",
    "cameraModelSTxt = r\"C:\\Users\\bmsha\\sc2025\\metadata_1\\camera_models.txt\"\n",
    "CameraMakerTxt = r\"C:\\Users\\bmsha\\sc2025\\metadata_1\\camera_makers.txt\"\n",
    "\n",
    "train_dataset = FungiDataset(train_df, image_path, cameraModelSTxt, CameraMakerTxt, transform=get_transforms(data='train'), multi_modal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef8067da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25863 [01:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#iterate through the dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset))):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     image, label, file_path, habitat, substrate, eventDate, latitude, longitude = train_dataset[i]\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, File path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Habitat: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhabitat\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Substrate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubstrate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Event Date: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meventDate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Latitude: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Longitude: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlongitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# You can add more processing or checks here as needed\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 8)"
     ]
    }
   ],
   "source": [
    "#iterate through the dataset\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    image, label, _, habitat, substrate, eventDate, latitude, longitude = train_dataset[i]\n",
    "    print(f\"Image shape: {image.shape}, Label: {label}, File path: {file_path}, Habitat: {habitat}, Substrate: {substrate}, Event Date: {eventDate}, Latitude: {latitude}, Longitude: {longitude}\")\n",
    "    # You can add more processing or checks here as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
